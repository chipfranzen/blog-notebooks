{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Bandit, a neural networks committee for the contextual bandit problem\n",
    "\n",
    "Charles Franzen\n",
    "\n",
    "5/9/17\n",
    "\n",
    "## Contextual Multi-armed bandits\n",
    "\n",
    "The contextual multi-armed bandit (MAB) problem can be quickly summarized as follows: a person is shown a context at timestep $t$ and asked to choose among $K$ actions. An action is chosen, a reward is revealed, and a new context is shown for the next timestep $t+1$. The problem is how to make a sequence of decisions about what action to take, given the context and history of contexts, actions and rewards. The goal is to maximize the payout.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "More formally, given a set of $K$ actions and a sequence of contexts $X = x_1, x_2, ..., x_t$, $x_t \\in \\mathbb{R}^n$ and rewards $R = r_1, r_2, ..., r_t$, $r_t \\in \\mathbb{R}^K$ of length $T$, choose actions at each timestep that maximize the total reward recieved.\n",
    "\n",
    "This problem is also an *adversarial* bandit problem, because no statistical assumptions are made about the reward distribution.\n",
    "\n",
    "In practice, rather than attempting to maximize reward, bandit algorithms attempt to minimize *regret*, which is the difference between the obtained rewards and the rewards obtained by the best possible strategy.\n",
    "\n",
    "NOTE: I use the terms 'action' and 'arm' interchangeably.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset I used to investigate contextual bandits is the UCI Covertype dataset. It consists of 580,000 data points, with 54 features and a target variable of 7 classes. The features represent various attributes of locations such as elevation, soil type, and amount of sunlight. The classes are forest cover types. To adapt this to the contextual bandit, the target was one-hot coded into length 7 reward vectors. The problem then is to move through the sequence of data points and make online decisions. If action 3 were selected based on some context, then only reward 3 is revealed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import functools\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging and exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'elevation',\n",
    "    'aspect',\n",
    "    'slope',\n",
    "    'h_dist_hydro',\n",
    "    'v_dist_hydro',\n",
    "    'h_dist_road',\n",
    "    'shade_9am',\n",
    "    'shade_noon',\n",
    "    'shade_3pm',\n",
    "    'h_dist_fire',\n",
    "]\n",
    "\n",
    "col_names += ['wild_' + str(i) for i in range(4)]\n",
    "col_names += ['soil_' + str(i) for i in range(40)]\n",
    "col_names.append('cover_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('covtype.data', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('soil_cover.pkl', mode='xb') as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>h_dist_hydro</th>\n",
       "      <th>v_dist_hydro</th>\n",
       "      <th>h_dist_road</th>\n",
       "      <th>shade_9am</th>\n",
       "      <th>shade_noon</th>\n",
       "      <th>shade_3pm</th>\n",
       "      <th>h_dist_fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_31</th>\n",
       "      <th>soil_32</th>\n",
       "      <th>soil_33</th>\n",
       "      <th>soil_34</th>\n",
       "      <th>soil_35</th>\n",
       "      <th>soil_36</th>\n",
       "      <th>soil_37</th>\n",
       "      <th>soil_38</th>\n",
       "      <th>soil_39</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  aspect  slope  h_dist_hydro  v_dist_hydro  h_dist_road  \\\n",
       "0       2596      51      3           258             0          510   \n",
       "1       2590      56      2           212            -6          390   \n",
       "2       2804     139      9           268            65         3180   \n",
       "3       2785     155     18           242           118         3090   \n",
       "4       2595      45      2           153            -1          391   \n",
       "\n",
       "   shade_9am  shade_noon  shade_3pm  h_dist_fire     ...      soil_31  \\\n",
       "0        221         232        148         6279     ...            0   \n",
       "1        220         235        151         6225     ...            0   \n",
       "2        234         238        135         6121     ...            0   \n",
       "3        238         238        122         6211     ...            0   \n",
       "4        220         234        150         6172     ...            0   \n",
       "\n",
       "   soil_32  soil_33  soil_34  soil_35  soil_36  soil_37  soil_38  soil_39  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   cover_type  \n",
       "0           5  \n",
       "1           5  \n",
       "2           2  \n",
       "3           2  \n",
       "4           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>aspect</th>\n",
       "      <th>slope</th>\n",
       "      <th>h_dist_hydro</th>\n",
       "      <th>v_dist_hydro</th>\n",
       "      <th>h_dist_road</th>\n",
       "      <th>shade_9am</th>\n",
       "      <th>shade_noon</th>\n",
       "      <th>shade_3pm</th>\n",
       "      <th>h_dist_fire</th>\n",
       "      <th>...</th>\n",
       "      <th>soil_31</th>\n",
       "      <th>soil_32</th>\n",
       "      <th>soil_33</th>\n",
       "      <th>soil_34</th>\n",
       "      <th>soil_35</th>\n",
       "      <th>soil_36</th>\n",
       "      <th>soil_37</th>\n",
       "      <th>soil_38</th>\n",
       "      <th>soil_39</th>\n",
       "      <th>cover_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365301</td>\n",
       "      <td>155.656807</td>\n",
       "      <td>14.103704</td>\n",
       "      <td>269.428217</td>\n",
       "      <td>46.418855</td>\n",
       "      <td>2350.146611</td>\n",
       "      <td>212.146049</td>\n",
       "      <td>223.318716</td>\n",
       "      <td>142.528263</td>\n",
       "      <td>1980.291226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984734</td>\n",
       "      <td>111.913721</td>\n",
       "      <td>7.488242</td>\n",
       "      <td>212.549356</td>\n",
       "      <td>58.295232</td>\n",
       "      <td>1559.254870</td>\n",
       "      <td>26.769889</td>\n",
       "      <td>19.768697</td>\n",
       "      <td>38.274529</td>\n",
       "      <td>1324.195210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>1.396504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           elevation         aspect          slope   h_dist_hydro  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean     2959.365301     155.656807      14.103704     269.428217   \n",
       "std       279.984734     111.913721       7.488242     212.549356   \n",
       "min      1859.000000       0.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000     108.000000   \n",
       "50%      2996.000000     127.000000      13.000000     218.000000   \n",
       "75%      3163.000000     260.000000      18.000000     384.000000   \n",
       "max      3858.000000     360.000000      66.000000    1397.000000   \n",
       "\n",
       "        v_dist_hydro    h_dist_road      shade_9am     shade_noon  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean       46.418855    2350.146611     212.146049     223.318716   \n",
       "std        58.295232    1559.254870      26.769889      19.768697   \n",
       "min      -173.000000       0.000000       0.000000       0.000000   \n",
       "25%         7.000000    1106.000000     198.000000     213.000000   \n",
       "50%        30.000000    1997.000000     218.000000     226.000000   \n",
       "75%        69.000000    3328.000000     231.000000     237.000000   \n",
       "max       601.000000    7117.000000     254.000000     254.000000   \n",
       "\n",
       "           shade_3pm    h_dist_fire      ...              soil_31  \\\n",
       "count  581012.000000  581012.000000      ...        581012.000000   \n",
       "mean      142.528263    1980.291226      ...             0.090392   \n",
       "std        38.274529    1324.195210      ...             0.286743   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%       119.000000    1024.000000      ...             0.000000   \n",
       "50%       143.000000    1710.000000      ...             0.000000   \n",
       "75%       168.000000    2550.000000      ...             0.000000   \n",
       "max       254.000000    7173.000000      ...             1.000000   \n",
       "\n",
       "             soil_32        soil_33        soil_34        soil_35  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.077716       0.002773       0.003255       0.000205   \n",
       "std         0.267725       0.052584       0.056957       0.014310   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             soil_36        soil_37        soil_38        soil_39  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.000513       0.026803       0.023762       0.015060   \n",
       "std         0.022641       0.161508       0.152307       0.121791   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          cover_type  \n",
       "count  581012.000000  \n",
       "mean        2.051471  \n",
       "std         1.396504  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         2.000000  \n",
       "max         7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['cover_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get X and Y\n",
    "X = df.values[:, :-7]\n",
    "Y = df.values[:, -7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/dl/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36460521,  0.48759922,  0.06153746,  0.00472796,  0.01633873,\n",
       "        0.02989095,  0.03530048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is highly imbalanced. Arms 0 and 1 make up the vast majority of rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.550458</td>\n",
       "      <td>0.432380</td>\n",
       "      <td>0.213692</td>\n",
       "      <td>0.192862</td>\n",
       "      <td>0.283487</td>\n",
       "      <td>0.330216</td>\n",
       "      <td>0.835221</td>\n",
       "      <td>0.879208</td>\n",
       "      <td>0.561135</td>\n",
       "      <td>0.276076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.140062</td>\n",
       "      <td>0.310871</td>\n",
       "      <td>0.113458</td>\n",
       "      <td>0.152147</td>\n",
       "      <td>0.075317</td>\n",
       "      <td>0.219089</td>\n",
       "      <td>0.105393</td>\n",
       "      <td>0.077830</td>\n",
       "      <td>0.150687</td>\n",
       "      <td>0.184608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205483</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.475238</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.077309</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.155403</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.468504</td>\n",
       "      <td>0.142758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.568784</td>\n",
       "      <td>0.352778</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.156049</td>\n",
       "      <td>0.262274</td>\n",
       "      <td>0.280596</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.889764</td>\n",
       "      <td>0.562992</td>\n",
       "      <td>0.238394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.652326</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.274875</td>\n",
       "      <td>0.312661</td>\n",
       "      <td>0.467613</td>\n",
       "      <td>0.909449</td>\n",
       "      <td>0.933071</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.550458       0.432380       0.213692       0.192862   \n",
       "std         0.140062       0.310871       0.113458       0.152147   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.475238       0.161111       0.136364       0.077309   \n",
       "50%         0.568784       0.352778       0.196970       0.156049   \n",
       "75%         0.652326       0.722222       0.272727       0.274875   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.283487       0.330216       0.835221       0.879208   \n",
       "std         0.075317       0.219089       0.105393       0.077830   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.232558       0.155403       0.779528       0.838583   \n",
       "50%         0.262274       0.280596       0.858268       0.889764   \n",
       "75%         0.312661       0.467613       0.909449       0.933071   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  8              9       ...                   44  \\\n",
       "count  581012.000000  581012.000000      ...        581012.000000   \n",
       "mean        0.561135       0.276076      ...             0.044175   \n",
       "std         0.150687       0.184608      ...             0.205483   \n",
       "min         0.000000       0.000000      ...             0.000000   \n",
       "25%         0.468504       0.142758      ...             0.000000   \n",
       "50%         0.562992       0.238394      ...             0.000000   \n",
       "75%         0.661417       0.355500      ...             0.000000   \n",
       "max         1.000000       1.000000      ...             1.000000   \n",
       "\n",
       "                  45             46             47             48  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.090392       0.077716       0.002773       0.003255   \n",
       "std         0.286743       0.267725       0.052584       0.056957   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  49             50             51             52  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.000205       0.000513       0.026803       0.023762   \n",
       "std         0.014310       0.022641       0.161508       0.152307   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  53  \n",
       "count  581012.000000  \n",
       "mean        0.015060  \n",
       "std         0.121791  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Bandit algorithm\n",
    "\n",
    "The algorithm that I've implemented is called Neural Bandit. I've implemented 2 iterations, henceforth called Neural Bandit 1 (NB1) and Neural Bandit 2 (NB2)\n",
    "\n",
    "### Neural Bandit 1\n",
    "\n",
    "This algorithm works by creating a Multilayer Perceptron (MLP) for each arm, then performing epsilon-greedy arm selection. Epsilon-greedy arm selection works by having every arm predict a reward based on an observed context, then choosing the best arm most of the time, with some probability of choosing a random arm. Once an arm has been chosen, play that arm and observe the reward. Perform a training step on the MLP for the arm played, and continue to the next timestep.\n",
    "\n",
    "Pseudocode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Algorithm 1: Neural Bandit 1\n",
    "\n",
    "\n",
    "    initialize a mulitlayer perceptron A_k for each action in action set K\n",
    "    choose exploration parameter epsilon\n",
    "    for t = 1, 2, ..., T:\n",
    "        observe context x_t \n",
    "        for k in K:\n",
    "            predict y_k from x_t using A_k\n",
    "        perform a Bernoulli trail with success probability epsilon\n",
    "        if success:\n",
    "            play arm with the highest predicted reward\n",
    "        else\n",
    "            play a random arm \n",
    "        perform a training step on the arm played\n",
    "        \n",
    "### A note on optimization\n",
    "\n",
    "The authors of Neural Bandit suggest altering the weight update equation for Stochastic Gradient Descent (SGD) by scaling the gradients by a factor $1-\\gamma + \\frac{\\gamma}{K}$, with exploration parameter $\\gamma \\in (0, 1]$, and number of actions $K$. I implemented their suggestion by altering Keras' built in optimizers, but performance was unstable, so I ended up just using the optimizers as implemented by Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "class Bandit_SGD(SGD):\n",
    "    \"\"\"Stochastic gradient descent optimizer for contextual bandits.\n",
    "    Includes support for momentum,\n",
    "    learning rate decay, and Nesterov momentum.\n",
    "    # Arguments\n",
    "        n_arms: int >0. Number of arms.\n",
    "        explore: float [0., .5] Exploration parameter.\n",
    "        lr: float >= 0. Learning rate.\n",
    "        momentum: float >= 0. Parameter updates momentum.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_arms=2., explore=.1, **kwargs):\n",
    "        super(Bandit_SGD, self).__init__(**kwargs)\n",
    "        self.n_arms = K.variable(n_arms, name='n_arms')\n",
    "        self.explore = K.variable(explore, name='explore')\n",
    "    \n",
    "    def get_updates(self, params, constraints, loss):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = []\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "            self.updates .append(K.update_add(self.iterations, 1))\n",
    "        \n",
    "        # weight scaling for bandits\n",
    "        P = (1. - self.explore) + self.explore / self.n_arms\n",
    "        # momentum\n",
    "        shapes = [K.get_variable_shape(p) for p in params]\n",
    "        moments = [K.zeros(shape) for shape in shapes]\n",
    "        self.weights = [self.iterations] + moments\n",
    "        for p, g, m in zip(params, grads, moments):\n",
    "            # apply bandit scaling\n",
    "            g =  g/P\n",
    "            v = self.momentum * m - lr * g  # velocity\n",
    "            self.updates.append(K.update(m, v))\n",
    "\n",
    "            if self.nesterov:\n",
    "                new_p = (p + self.momentum * v - lr * g)\n",
    "            else:\n",
    "                new_p = (p + v)\n",
    "\n",
    "            # apply constraints\n",
    "            if p in constraints:\n",
    "                c = constraints[p]\n",
    "                new_p = c(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "    \n",
    "class Bandit_Adam(Adam):\n",
    "    \"\"\"Adam optimizer for contextual bandits\n",
    "    Default parameters follow those provided in the original paper.\n",
    "    # Arguments\n",
    "        n_arms: int >0. Number of arms.\n",
    "        explore: float [0., .5] Exploration parameter.\n",
    "        lr: float >= 0. Learning rate.\n",
    "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
    "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
    "        epsilon: float >= 0. Fuzz factor.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "    # References\n",
    "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_arms=2., explore=.1, **kwargs):\n",
    "        super(Bandit_Adam, self).__init__(**kwargs)\n",
    "        self.n_arms = K.variable(n_arms, name='n_arms')\n",
    "        self.explore = K.variable(explore, name='explore')\n",
    "        \n",
    "\n",
    "    def get_updates(self, params, constraints, loss):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr *= (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "        t = self.iterations + 1\n",
    "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
    "                     (1. - K.pow(self.beta_1, t)))\n",
    "\n",
    "        shapes = [K.get_variable_shape(p) for p in params]\n",
    "        ms = [K.zeros(shape) for shape in shapes]\n",
    "        vs = [K.zeros(shape) for shape in shapes]\n",
    "        self.weights = [self.iterations] + ms + vs\n",
    "        # weight scaling for bandits\n",
    "        P = (1. - self.explore)*(loss > -0.6931471805599453) + self.explore / self.n_arms\n",
    "        \n",
    "        for p, g, m, v in zip(params, grads, ms, vs):\n",
    "            # apply bandit scaling\n",
    "            g = g/P\n",
    "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
    "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
    "            p_t = p - lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
    "\n",
    "            self.updates.append(K.update(m, m_t))\n",
    "            self.updates.append(K.update(v, v_t))\n",
    "\n",
    "            new_p = p_t\n",
    "            # apply constraints\n",
    "            if p in constraints:\n",
    "                c = constraints[p]\n",
    "                new_p = c(new_p)\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building NB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                1760      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,793.0\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# mlp factory\n",
    "\n",
    "def build_experts(n, input_shape, n_hidden, n_layers):\n",
    "    # builds a committee of experts\n",
    "    def build_expert():\n",
    "        model = Sequential()\n",
    "        # add hidden layers\n",
    "        for layer in range(n_layers):\n",
    "            model.add(Dense(n_hidden,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            activation='relu',\n",
    "                            input_dim=input_shape,\n",
    "                            kernel_regularizer=regularizers.l2(0.01)))\n",
    "        # output layer\n",
    "        model.add(Dense(1,\n",
    "                        kernel_initializer='glorot_normal',\n",
    "                        activation='sigmoid',\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))\n",
    "        return model\n",
    "    experts = [build_expert() for i in range(n)]\n",
    "    return experts\n",
    "\n",
    "experts = build_experts(4, X.shape[1], 32, 1)\n",
    "experts[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.models.Sequential at 0x11440a5f8>,\n",
       " <keras.models.Sequential at 0x10280e5f8>,\n",
       " <keras.models.Sequential at 0x115553b00>,\n",
       " <keras.models.Sequential at 0x1155ad4a8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compile_experts(experts, optimizer, loss, **kwargs):\n",
    "    # compiles a commitee of experts\n",
    "    n_arms = len(experts)\n",
    "    def compile_expert(expert, **kwargs):\n",
    "        expert.compile(optimizer=optimizer,\n",
    "                      loss=loss)\n",
    "        return expert\n",
    "    compiled_experts = [compile_expert(expert) for expert in experts]\n",
    "    return compiled_experts\n",
    "\n",
    "# test it out\n",
    "experts = compile_experts(experts, 'adam', 'binary_crossentropy', explore=.1)\n",
    "experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD3CAYAAADfYKXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11593b198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chooses an arm as in Algorithm 1\n",
    "def choose_arm(x, experts, explore):\n",
    "    n_arms = len(experts)\n",
    "    # make predictions\n",
    "    preds = [expert.predict(x) for expert in experts]\n",
    "    # get best arm\n",
    "    arm_max = np.nanargmax(preds)\n",
    "    # create arm selection probabilities\n",
    "    P = [(1-explore)*(arm==arm_max) + explore/n_arms for arm in range(n_arms)]\n",
    "    # select an arm\n",
    "    chosen_arm = np.random.choice(np.arange(n_arms), p=P)\n",
    "    pred = preds[chosen_arm]\n",
    "    return chosen_arm, pred\n",
    "\n",
    "# quick test\n",
    "starting_arms = pd.value_counts([choose_arm(X[[np.random.choice(range(X.shape[0]))]], experts, explore=.5)[0] for i in range(10)])\n",
    "sns.barplot(starting_arms.index, starting_arms.values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model\n",
    "\n",
    "I ran the models on the full dataset using a p2.xlarge GPU instance on AWS. These runs are from my local machine to show that the code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_bandit_1(X, Y, explore, exp_annealing_rate=1, min_explore=.005, **kwargs):\n",
    "    n, n_arms = Y.shape\n",
    "    input_shape = X.shape[1]\n",
    "    experts = build_experts(n_arms, input_shape, 32, 1)\n",
    "    experts = compile_experts(experts, **kwargs)\n",
    "    # trace for arm choices\n",
    "    chosen_arms = []\n",
    "    # trace for regrets\n",
    "    regrets = []\n",
    "    true_rewards = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    message_iteration = 10\n",
    "    print(f'Starting bandit\\n----------\\nN_arms: {n_arms}\\n----------\\n')\n",
    "    for i in range(n):\n",
    "        context = X[[i]]\n",
    "        chosen_arm, pred = choose_arm(context, experts, explore)\n",
    "        reward = Y[i, chosen_arm]\n",
    "        max_reward = np.max(Y[i])\n",
    "        max_arm = np.argmax(Y[i])\n",
    "        true_rewards.append(max_arm)\n",
    "        expert = experts[chosen_arm]\n",
    "        expert.fit(context, np.expand_dims(reward, axis=0), epochs=1, verbose=0)\n",
    "        experts[chosen_arm] = expert\n",
    "        chosen_arms.append(chosen_arm)\n",
    "        regret = max_reward - reward\n",
    "        regrets.append(regret)\n",
    "        if explore > min_explore:\n",
    "            explore *= exp_annealing_rate\n",
    "        if (i % message_iteration == 0) and (i > 0):\n",
    "            if message_iteration <= 1e4:\n",
    "                message_iteration *= 10\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = (n*elapsed/i - elapsed)/60\n",
    "            print(f'''Completed iteration: {i}\n",
    "            Elapsed time: {elapsed:.2f} seconds\n",
    "            Estimated time remaining: {remaining:.2f} minutes\n",
    "            --------------------''')\n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Finished in: {elapsed:.2f} minutes')\n",
    "    return experts, chosen_arms, true_rewards, regrets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting bandit\n",
      "----------\n",
      "N_arms: 7\n",
      "----------\n",
      "\n",
      "Completed iteration: 10\n",
      "            Elapsed time: 6.69 seconds\n",
      "            Estimated time remaining: 1.00 minutes\n",
      "            --------------------\n",
      "Finished in: 0.16 minutes\n"
     ]
    }
   ],
   "source": [
    "# sample run\n",
    "n_points = 100\n",
    "\n",
    "fit_models_1, arm_hist_1, true_reward_hist_1, regret_hist_1 = run_bandit_1(X[:n_points], Y[:n_points], optimizer='adam', loss='binary_crossentropy', explore=.005, exp_annealing_rate=1, clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCRAFPoiIgGi0BcRCZD/D58GHf/Gg4fCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a25d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.plt.plot(np.cumsum(regret_hist_1))\n",
    "sns.plt.title('cumulative regret')\n",
    "sns.plt.xlabel('$t$')\n",
    "sns.plt.ylabel('regret');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50\n",
       "0    34\n",
       "2     8\n",
       "5     4\n",
       "6     3\n",
       "4     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true best arms\n",
    "pd.value_counts(true_reward_hist_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    33\n",
       "3    21\n",
       "5    16\n",
       "0    15\n",
       "4    11\n",
       "2     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chosen arms\n",
    "pd.value_counts(arm_hist_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAETCAYAAADah9Z7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a431f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(pd.value_counts(arm_hist_1).index, pd.value_counts(arm_hist_1).values)\n",
    "plt.title('chosen arm distribution')\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('arm');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAETCAYAAADah9Z7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wvXI8V7QCdLsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a12ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(pd.value_counts(true_reward_hist_1).index, pd.value_counts(true_reward_hist_1).values)\n",
    "plt.title('true reward distribution')\n",
    "plt.ylabel('reward')\n",
    "plt.xlabel('arm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Bandit 2\n",
    "\n",
    "NB2 is an extension of NB1. Neural networks have a large number of hyperparameters, from architecture to choice of optimization algorthim to regularization. In the contextual bandit problem, however, it's not possible to grid search, since decisions must be made online and consequently only one pass through the dataset is allowed. Hyperparameter selection is instead handled by the Exp3 algorithm, which stands for \"Exponential-weight algorithm for Exploration and Exploitation\". This is a general algorithm for adversarial bandits. A weight vector is maintained witha weight for each action. Actions are chosen probabilistically based on the weights, with larger weighted actions having a higher probability of being chosen. There is also an exploration parameter, which determines how random the action chioce is.\n",
    "\n",
    "With weights initialized to $w_i = 1$ for $i = 1, ..., K$, and exploration parameter $\\gamma \\in (0, 1]$, the probability of playing action $i$ at timestep $t$ is \n",
    "\n",
    "(1)\n",
    "$$p_{i, t} = (1-\\gamma)\\frac{w_{i, t}}{\\sum^K_{j=1}w_{j, t}}+\\frac{\\gamma}{K} $$\n",
    "\n",
    "After action $i$ is played and reward $r_i$ is revealed, the weight of arm $i$ is updated to:\n",
    "\n",
    "(2)\n",
    "$$w_{i, t+1} = w_{i, t}\\exp{\\left(\\frac{\\gamma r_i}{p_{i, t}K}\\right)} $$\n",
    "\n",
    "This is adapted for Neural Bandit by instantiating some number of models according to NB1, varying architectures and hyperparameters, maintaining a weight vector for these models, and choosing a model to play at each timestep $t$. The arm is then chosen as in NB1 and a reward observed. *Each model* then performs a training step for the chosen arm with context $x_t$ and reward $r_{i, t}$. This way multiple models are trained online and the best model is asked to pick the arm more often as Exp3 weights evolve.\n",
    "\n",
    "Pseudocode:\n",
    "\n",
    "    Algorithm 2: Neural Bandit 2\n",
    "    \n",
    "    choose exploration parameter gamma\n",
    "    create M models\n",
    "    initialize M Neural Bandit 1\n",
    "    initialize Exp3 weight vector to all ones\n",
    "    for t in 1, 2, ..., T:\n",
    "        observe context x_t\n",
    "        draw m_t from P_model as in equation (1)\n",
    "        model m_t chooses action k_t\n",
    "        reveal reward r_kt\n",
    "        perform a training step for action k_t for each model\n",
    "        update the Exp3 weight for m_t as in equation (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural bandit 2\n",
    "\n",
    "# get shapes and number of arms\n",
    "n, n_arms = Y.shape\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "# init models\n",
    "# 32 hidden units, 1 hidden layer, explore = .005\n",
    "model_1 = build_experts(n_arms, input_shape, n_hidden=32, n_layers=1)\n",
    "model_1 = compile_experts(model_1, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 64 hidden units, 1 hidden layer, explore = .005\n",
    "model_2 = build_experts(n_arms, input_shape, n_hidden=64, n_layers=1)\n",
    "model_2 = compile_experts(model_2, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 128 hidden units, 1 hidden layer, explore = .005\n",
    "model_3 = build_experts(n_arms, input_shape, n_hidden=128, n_layers=1)\n",
    "model_3 = compile_experts(model_3, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 64 hidden units, 2 hidden layers, explore = .005\n",
    "model_4 = build_experts(n_arms, input_shape, n_hidden=64, n_layers=2)\n",
    "model_4 = compile_experts(model_4, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 64 hidden units, 2 hidden layers, explore = .005\n",
    "model_5 = build_experts(n_arms, input_shape, n_hidden=128, n_layers=2)\n",
    "model_5 = compile_experts(model_5, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 32 hidden units, 1 hidden layer, annealing_explore\n",
    "model_6 = build_experts(n_arms, input_shape, n_hidden=32, n_layers=1)\n",
    "model_6 = compile_experts(model_6, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 64 hidden units, 1 hidden layer, annealing_explore\n",
    "model_7 = build_experts(n_arms, input_shape, n_hidden=64, n_layers=1)\n",
    "model_7 = compile_experts(model_7, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# 128 hidden units, 1 hidden layer, annealing_explore\n",
    "model_8 = build_experts(n_arms, input_shape, n_hidden=128, n_layers=1)\n",
    "model_8 = compile_experts(model_8, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 64 hidden units, 2 hidden layers, annealing_explore\n",
    "model_9 = build_experts(n_arms, input_shape, n_hidden=64, n_layers=2)\n",
    "model_9 = compile_experts(model_9, loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "\n",
    "# 64 hidden units, 2 hidden layers, annealing_explore\n",
    "model_10 = build_experts(n_arms, input_shape, n_hidden=128, n_layers=2)\n",
    "model_10 = compile_experts(model_10, loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 complete in 23.778280019760132 seconds.\n",
      "Step 2 complete in 23.80380392074585 seconds.\n",
      "Step 4 complete in 34.6318678855896 seconds.\n",
      "Step 8 complete in 53.786434173583984 seconds.\n",
      "Step 16 complete in 62.28660321235657 seconds.\n",
      "Step 32 complete in 68.92496013641357 seconds.\n",
      "Step 64 complete in 69.78483510017395 seconds.\n"
     ]
    }
   ],
   "source": [
    "# set n_steps and model exploration parameter\n",
    "n_steps = 100\n",
    "gamma_model=.1\n",
    "\n",
    "# collect models, only 4 in the interest of time\n",
    "models = [model_2, model_4, model_7, model_9]\n",
    "n_models = len(models)\n",
    "# init weight vector\n",
    "weights = np.ones(n_models)\n",
    "# init model explore parameters\n",
    "explores = np.array([.005]*2 + [.5]*2)\n",
    "anneal = np.array([False]*2 + [True]*2)\n",
    "annealing_rate = .99995\n",
    "min_explore = .005\n",
    "\n",
    "def get_model_probabilities(weights, gamma_model):\n",
    "    # get probabilites of choosing each model\n",
    "    p = np.array([(1-gamma_model)*weight/sum(weights) + gamma_model/n_models for weight in weights])\n",
    "    return p\n",
    "\n",
    "def choose_model(weights, gamma_model, model_probabilities):\n",
    "    # choose a model based on weights\n",
    "    n_models = len(weights)\n",
    "    model = np.random.choice(np.arange(n_models), p=model_probabilities)\n",
    "    return model\n",
    "\n",
    "# init histories\n",
    "arm_hist_2 = []\n",
    "model_hist_2 = []\n",
    "regret_hist_2 = []\n",
    "weight_hist_2 = []\n",
    "\n",
    "# init timing vars\n",
    "start_time = time.time()\n",
    "next_check = 1\n",
    "\n",
    "# train the models\n",
    "for step in range(n_steps):\n",
    "    # store weights\n",
    "    weight_hist_2.append(weights)\n",
    "    # get probs and choose a model\n",
    "    p = get_model_probabilities(weights, gamma_model)\n",
    "    chosen_model = choose_model(weights, gamma_model, p)\n",
    "    # store model choice\n",
    "    model_hist_2.append(chosen_model)\n",
    "    # get a random data point\n",
    "    i = np.random.randint(X.shape[0])\n",
    "    context = X[[i]]\n",
    "    # choose an arm\n",
    "    chosen_arm, pred = choose_arm(context, models[chosen_model], explores[chosen_model])\n",
    "    # store arm selection\n",
    "    arm_hist_2.append(chosen_arm)\n",
    "    # observe reward and max reward\n",
    "    reward = Y[i, chosen_arm]\n",
    "    max_reward = np.max(Y[i])\n",
    "    # calculate and store regret\n",
    "    regret = max_reward - reward\n",
    "    regret_hist_2.append(regret)\n",
    "    # update the chosen arm for each model\n",
    "    for m, model in enumerate(models):\n",
    "        expert = model[chosen_arm]\n",
    "        expert.fit(context, np.expand_dims(reward, axis=0), epochs=1, verbose=0)\n",
    "        model[chosen_arm] = expert\n",
    "        # anneal explore param if necessary\n",
    "        if (anneal[m]) and (explores[m] > min_explore):\n",
    "            explores[m] *= annealing_rate\n",
    "    # update weights\n",
    "    weights[chosen_model] = weights[chosen_model]*np.exp((gamma_model*reward/(p[chosen_model]*n_models)))\n",
    "    # print progress\n",
    "    if step == next_check:\n",
    "        elapsed = time.time()-start_time\n",
    "        print(f'Step {step} complete in {elapsed} seconds.')\n",
    "        next_check *= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow implementation and multi-task learning\n",
    "\n",
    "I had an idea for NB1 models to have a shared layer before branching for each arm, with the idea that updating shared weights would allow the other arms to learn even when they aren't chosen and therefore do not observe a context and reward. This shared layer is refered to as Multi-task learning. It was necessary to implement this in TensorFlow, and the results are somewhat promising, but I have not yet integrated this NB1 architecture into NB2. That would be a logical extension of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow version of Neural Bandit 1\n",
    "\n",
    "N_EXPERTS = 7\n",
    "N_FEATURES = X.shape[1]\n",
    "N_HIDDEN = 128\n",
    "MAX_STEPS = len(X)\n",
    "START_EXPLORE = np.array([.005])\n",
    "\n",
    "graph2 = tf.Graph()\n",
    "with graph2.as_default():\n",
    "    \n",
    "    # placeholders for inputs, rewards\n",
    "    context = tf.placeholder(tf.float32,\n",
    "                             shape=[None, N_FEATURES],\n",
    "                             name='context')\n",
    "    reward = tf.placeholder(tf.float32,\n",
    "                            shape=[None, N_EXPERTS],\n",
    "                            name='reward')\n",
    "    \n",
    "    # setting the exploration parameter and annealing rate\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    \n",
    "    start_explore = tf.constant(dtype=tf.float32,\n",
    "                          name='explore',\n",
    "                          shape=[1],\n",
    "                          value=START_EXPLORE)\n",
    "    min_explore = tf.constant([.005],\n",
    "                              dtype=tf.float32,\n",
    "                              name='min_explore')\n",
    "    \n",
    "    explore_anneal = tf.constant([.99995],\n",
    "                                 dtype=tf.float32,\n",
    "                                 name='explore_annealing_rate')\n",
    "    \n",
    "    explore = start_explore * tf.pow(explore_anneal, tf.to_float(global_step + 1))\n",
    "    \n",
    "    explore = tf.maximum(explore, min_explore)\n",
    "    \n",
    "    \n",
    "    # initializing regret\n",
    "    cum_regret = tf.Variable([0], dtype=tf.int32, name='regret', trainable=False)\n",
    "    \n",
    "    \n",
    "    def build_arm_network(activations, n_hidden):\n",
    "        W1 = tf.Variable(tf.truncated_normal([n_hidden, n_hidden], stddev=.1),\n",
    "                        dtype=tf.float32,\n",
    "                        name='W1',)\n",
    "        B1 = tf.Variable(tf.truncated_normal([n_hidden], stddev=.1),\n",
    "                        dtype=tf.float32,\n",
    "                        name='B1')\n",
    "        W2 = tf.Variable(tf.truncated_normal([n_hidden, 1], stddev=.1),\n",
    "                         dtype=tf.float32,\n",
    "                         name='W2')\n",
    "        B2 = tf.Variable(tf.truncated_normal([1], stddev=.1),\n",
    "                         dtype=tf.float32,\n",
    "                         name='B2')\n",
    "        h1 = tf.matmul(activations, W1) + B1\n",
    "        a1 = tf.nn.relu(h1)\n",
    "        h2 = tf.matmul(a1, W2) + B2\n",
    "        return h2\n",
    "    \n",
    "    def loss_fn(target, y_hat):\n",
    "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n",
    "                                                            logits=y_hat,\n",
    "                                                            name='xentropy')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "        return loss\n",
    "    \n",
    "    # dense layer variables\n",
    "    W_shared = tf.Variable(tf.truncated_normal([N_FEATURES, N_HIDDEN], stddev=.1),\n",
    "                           dtype=tf.float32,\n",
    "                           name='shared_weights',)\n",
    "\n",
    "    B_shared = tf.Variable(tf.truncated_normal([N_HIDDEN], stddev=.1),\n",
    "                           dtype=tf.float32,\n",
    "                           name='shared_biases')\n",
    "    \n",
    "    h_shared = tf.matmul(context, W_shared) + B_shared\n",
    "    a_shared = tf.nn.relu(h_shared)\n",
    "    \n",
    "    y_hats = []\n",
    "    for exp in range(N_EXPERTS):\n",
    "        \n",
    "        # arm networks\n",
    "        with tf.variable_scope('arm_'+str(exp)):\n",
    "            h = build_arm_network(a_shared, N_HIDDEN)\n",
    "            y_hat = tf.nn.sigmoid(h, name='y_hat')\n",
    "            y_hats.append(y_hat)\n",
    "            loss = loss_fn(tf.slice(reward, begin=[0, exp], size=[1, 1]), y_hat)\n",
    "\n",
    "            # track losses\n",
    "            tf.summary.scalar('loss', loss)\n",
    "        \n",
    "        \n",
    "    # aggregate predictions for epsilon greedy\n",
    "    y_hats = tf.squeeze(tf.concat(y_hats, axis=0))\n",
    "    \n",
    "    # epsilon greedy arm choice\n",
    "    best_arm = tf.arg_max(y_hats, dimension=0)\n",
    "    best_arm_probs = tf.expand_dims(tf.concat([explore, 1 - explore], axis=0), 0)\n",
    "    best_arm_draw = tf.squeeze(tf.multinomial(tf.log(best_arm_probs), 1))\n",
    "    \n",
    "    def best_arm_fn():\n",
    "        return best_arm\n",
    "    \n",
    "    def random_arm():\n",
    "        counts = tf.ones([1, N_EXPERTS])\n",
    "        logs = tf.log(counts)\n",
    "        return tf.squeeze(tf.multinomial(logs, 1))\n",
    "    \n",
    "    chosen_arm = tf.cond(tf.equal(best_arm_draw, tf.ones_like(best_arm_draw)), # condition\n",
    "                                  best_arm_fn, # if True\n",
    "                                  random_arm) # if False\n",
    "    \n",
    "    tf.summary.histogram('chosen_arms', chosen_arm)\n",
    "    \n",
    "    # track regret\n",
    "    true_best_arm = tf.arg_max(reward, dimension=1)\n",
    "    regret = tf.logical_not(tf.equal(chosen_arm, true_best_arm))\n",
    "    cum_regret = tf.assign(cum_regret, (tf.add(tf.to_int32(regret), cum_regret)))\n",
    "    tf.summary.scalar('cumulative_regret', tf.squeeze(cum_regret))\n",
    "    \n",
    "    \n",
    "    # create optimizers and training ops for each arm\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    update_ops.append(cum_regret)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        optimizers = [tf.train.AdamOptimizer() for _ in range(N_EXPERTS)]\n",
    "        \n",
    "        train_ops = []\n",
    "        for exp in range(N_EXPERTS):\n",
    "            with tf.variable_scope('arm'+str(exp)):\n",
    "                train_ops.append(optimizers[exp].minimize(loss, global_step))\n",
    "    \n",
    "    def train_op(arm):\n",
    "        return train_ops[arm]\n",
    "    \n",
    "    # tensorboard logs\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(graph=graph2, logdir='./neural_bandit_1')\n",
    "\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at step 0, regret was [0] and explore was [ 0.005]\n",
      "at step 100, regret was [92] and explore was [ 0.005]\n",
      "at step 200, regret was [184] and explore was [ 0.005]\n",
      "at step 300, regret was [270] and explore was [ 0.005]\n",
      "at step 400, regret was [368] and explore was [ 0.005]\n",
      "at step 500, regret was [467] and explore was [ 0.005]\n",
      "at step 600, regret was [561] and explore was [ 0.005]\n",
      "at step 700, regret was [661] and explore was [ 0.005]\n",
      "at step 800, regret was [758] and explore was [ 0.005]\n",
      "at step 900, regret was [858] and explore was [ 0.005]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph2) as sess:\n",
    "    sess.run(init_op)\n",
    "    for step in range(1000):\n",
    "        i = np.random.randint(X.shape[0])\n",
    "        feed_dict={context: X[[i]], reward: Y[[i]]}\n",
    "        chosen_arm_, y_hats_= sess.run([chosen_arm, y_hats], feed_dict=feed_dict)\n",
    "        if step % 100 == 0:\n",
    "            summary, _, regret_, explore_ = sess.run([merged, train_op(chosen_arm_), cum_regret, explore], feed_dict=feed_dict)\n",
    "            writer.add_summary(summary, step)\n",
    "            print('at step {}, regret was {} and explore was {}'.format(step, regret_, explore_))\n",
    "        else:\n",
    "            sess.run([train_op(chosen_arm_)], feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results\n",
    "\n",
    "Again, I fit the models using AWS GPU instances configured with the BitFusion Ubuntu 14 AMI. NB1 with a shared layer achieved an average regret of .409 per timestep over 100,000 timesteps, diminishing to .318 after 2 million. NB2 with 4 models, each varying the number of hidden units and number of hidden layers, acheived an average regret of .385 per timestep after 100,000 timesteps. Random arm choice gives an average regret of .857. There are numerical stability issues with the Exp3 algorithm, as weights have a tendency to overflow, limiting the number of timesteps that can be run. Dividing the weights by the lowest weight at set intervals can constrain the weights somewhat, but if the difference in performance between the best and worst model is too large the weights still run into overflow. See the regret trajectories below.\n",
    "\n",
    "![alt text](nb2_chosen_arms.png)\n",
    "\n",
    "![alt text](true_rewards.png)\n",
    "\n",
    "![alt text](nb2_regret.png)\n",
    "\n",
    "\n",
    "## Further research\n",
    "\n",
    "Shared layers should be incorporated into NB2 models. The authors of Neural Bandit also suggest Neural Bandit 3, in which a separate Exp3 instance is maintained for each arm. NB3 was theorized to be more robust to nonstationarity. Variants of Exp3 should be tried as well, and there are many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Auer, Peter, et al. \"The nonstochastic multiarmed bandit problem.\" SIAM journal on computing 32.1 (2002): 48-77.\n",
    "\n",
    "* https://jeremykun.com/2013/11/08/adversarial-bandits-and-the-exp3-algorithm/\n",
    "\n",
    "* Allesiardo, Robin, Raphaël Féraud, and Djallel Bouneffouf. \"A neural networks committee for the contextual bandit problem.\" International Conference on Neural Information Processing. Springer International Publishing, 2014.\n",
    "\n",
    "* Caruana, Rich. \"Multitask learning.\" Learning to learn. Springer US, 1998. 95-133."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "env": {},
   "language": "python",
   "name": "python3"
  },
  "nikola": {
   "category": "",
   "date": "2017-06-14 07:18:50 UTC+08:00",
   "description": "",
   "link": "",
   "slug": "neural-networks-for-contextual-multi-armed-bandits",
   "tags": "",
   "title": "Neural Networks for Contextual Multi-armed Bandits",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
