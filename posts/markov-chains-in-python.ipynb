{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Markov Chains in Python 3\n",
    "\n",
    "Markov chains are random processes wherein state-changes occur according to some probablility function.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "Markov chains can be visualized as graphs, with weights along the edges representing the probability of each state change. Here's an example of a relatively simple three-state markov chain: ![](/images/markov_diagram.png)\n",
    "\n",
    "An intuitive way to represent such a system is with a python dictionary, with each state as a key and values that map each node that the key state is connected with to the probablility that it will change to that node. In the example above, the key 'B' would have a value that maps .4 to 'A' and .6 to 'C'.\n",
    "\n",
    "Numpy arrays (alternative: lists of 2 lists) provide a convenient way to map probabilities to connected nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "state_dict = {'A': np.array([['A', 'B', 'C'],\n",
    "                             [.2, .4, .4]]),\n",
    "              'B': np.array([['A', 'C'],\n",
    "                             [.4, .6]]),\n",
    "              'C': np.array([['A', 'B'],\n",
    "                             [.6, .4]])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the state dictionary defined, it's straight-forward to build a markov-chain class based on this structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Markov(object):\n",
    "\n",
    "    def __init__(self, state_dict):\n",
    "        self.state_dict = state_dict\n",
    "        self.state = list(self.state_dict.keys())[0]\n",
    "\n",
    "    def check_state(self):\n",
    "        print('Current State: %s' % (self.state))\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "        print('State is now: %s' % (self.state))\n",
    "\n",
    "    def next_state(self):\n",
    "        A = self.state_dict[self.state]\n",
    "        self.state = np.random.choice(a=list(A[0]), p=list(A[1]))\n",
    "        print('New State: %s' % (self.state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.choice makes for an extremely convenient way to sample randomly from the probablility destribution defined in the state dictionary. The argument *a* is a list of elements and *p* is the corresponding list of probabilities. The class methods can be seen in action below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current State: B\n"
     ]
    }
   ],
   "source": [
    "diagram_a = Markov(state_dict)\n",
    "diagram_a.check_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State is now: B\n"
     ]
    }
   ],
   "source": [
    "diagram_a.set_state('B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New State: B\n",
      "New State: A\n",
      "New State: A\n",
      "New State: A\n",
      "New State: B\n",
      "New State: C\n",
      "New State: A\n",
      "New State: A\n",
      "New State: B\n",
      "New State: A\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    diagram_a.next_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2016-01-11 21:17:50 UTC+08:00",
   "description": "",
   "link": "",
   "slug": "markov-chains-in-python",
   "tags": "python, statistics",
   "title": "Markov Chains in Python",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
