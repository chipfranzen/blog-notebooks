{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression- Gradient Descent\n",
    "\n",
    "As the number of features used in regression increases, the matrix operations required by the closed-form solution become computationaly expensive, if not impossible.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "In fact, the computational complexity for the closed-from solution is $$O\\left( n^{3}\\right)$$ where *n* is the number of features. In cases with many features, an optimization algorithm is needed instead, and gradient descent is one of the most commonly used.\n",
    "\n",
    "In gradient descent, estimations of coeffients of a model equation are iteratively updated based upon the current gradient of the function, descending a loss function until the gradient is near zero. ![Visualization of gradient descent optimization](/images/gradient.png)\n",
    "\n",
    "For multiple linear regression the cost function is the residual sum of squares (RSS) of the model when applied to the test set.\n",
    "\n",
    "With true outputs **y**, feature coefficient vector **w**(*t*) at iteration *t*, and learning rate *Æž*, the updated coeffiencents are given by: \n",
    "\n",
    "\n",
    "$$\\mathbf w^{\\left( t+1\\right)}=\\mathbf w^{\\left( t\\right)}-\\eta \\nabla RSS\\left( \\mathbf w^{\\left( t\\right)}\\right)$$ With data by feature matrix **H**, $$\\nabla RSS\\left( \\mathbf w^{\\left( t\\right)}\\right) = \\nabla \\left[\\left( \\mathbf y-\\mathbf H\\mathbf w^{\\left( t\\right)}\\right)^{T}\\left( \\mathbf y - \\mathbf H \\mathbf w^{\\left( t\\right)}\\right)\\right]$$\n",
    "$$ = -2 \\mathbf H^{T}\\left( \\mathbf y - \\mathbf H\\mathbf w^{\\left( t\\right)}\\right)$$\n",
    "This yields the final derivation:\n",
    "$$\\mathbf w^{\\left( t+1\\right)}=\\mathbf w^{\\left( t\\right)}+2\\eta\\left[\\mathbf H^{T}\\left(\\mathbf y - \\mathbf H\\mathbf w^{\\left( t\\right)}\\right)\\right]$$\n",
    "\n",
    "Here is some pseudocode for the algorithm to translate from mathese into codespeak:\n",
    "\n",
    "```\n",
    "\n",
    "initialize coefficients\n",
    "\n",
    "while gradient_magnitude >= tolerance:\n",
    "    for each feature:\n",
    "        updated_feature_coefficient = feature_coefficient - eta*feature_derivative\n",
    "return coefficients\n",
    "```\n",
    "\n",
    "Now for the Python implementation:\n",
    "\n",
    "First import libraries and create functions to make predictions based on the model coefficients and yeild the errors based upon those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def predict_output(feature_matrix, coefficients):\n",
    "    ''' Returns an array of predictions\n",
    "    \n",
    "    inputs - \n",
    "        feature_matrix - 2-D array of dimensions data points by features\n",
    "        coefficients - 1-D array of estimated feature coefficients\n",
    "        \n",
    "    output - 1-D array of predictions\n",
    "    '''\n",
    "    predictions = np.dot(feature_matrix, coefficients)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a function to compute the partial derivative for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2*np.dot(errors, feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to write the main function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent_regression(H, y, initial_coefficients, eta, epsilon, max_iterations=10000):\n",
    "    ''' Returns coefficients for multiple linear regression.\n",
    "    \n",
    "    inputs - \n",
    "        H - 2-D array of dimensions data points by features\n",
    "        y - 1-D array of true output\n",
    "        initial_coefficients - 1-D array of initial coefficients\n",
    "        eta - float, the step size eta\n",
    "        epsilon - float, the tolerance at which the algorithm will terminate\n",
    "        max_iterations - int, tells the program when to terminate\n",
    "    \n",
    "    output - 1-D array of estimated coefficients\n",
    "    '''\n",
    "    converged = False\n",
    "    w = initial_coefficients\n",
    "    iteration = 0\n",
    "    while not converged:\n",
    "        if iteration > max_iterations:\n",
    "            print 'Exceeded max iterations\\nCoefficients: ', w\n",
    "            return w\n",
    "        pred = predict_output(H, w)\n",
    "        residuals = pred-y\n",
    "        gradient_sum_squares = 0\n",
    "        for i in range(len(w)):\n",
    "            partial = feature_derivative(residuals, H[:, i])\n",
    "            gradient_sum_squares += partial**2\n",
    "            w[i] = w[i] - eta*partial\n",
    "        gradient_magnitude = math.sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < epsilon:\n",
    "            converged = True\n",
    "        iteration += 1\n",
    "    print w\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out! I'll use a noisy sine function and try to fit a third degree polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x105b53bd0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEgYIQAACft/Kw7S9CJOhdQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105aa84d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(1)\n",
    "n = 20\n",
    "pts = [x/5. for x in xrange(n)]\n",
    "X = np.array(pts)\n",
    "y = np.array([math.sin(x) for x in pts]) + [random.gauss(0,1.0/3.0) for i in xrange(n)]\n",
    "\n",
    "plt.plot(X, y, '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to build the feature matrix with one column for each feature. The regression model will return coefficients **w** that minimize the RSS of the model: $$\\hat {y}_{i}=w_{0}+w_{1}x_{i}+w_{2}x^{2}_{i}+w_{3}x_{i}^{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_matrix = np.zeros(n*4)\n",
    "feature_matrix.shape = (n, 4)\n",
    "feature_matrix[:,0] = 1\n",
    "feature_matrix[:,1] = X\n",
    "feature_matrix[:,2] = X**2\n",
    "feature_matrix[:,3] = X**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to run the regression. Choosing *Æž* and *É›* is a bit of an art. Choosing a small learning rate will lead to a more precise answer, but if the learning rate is too small, the optimization may take a very long time. Conversely, a larger learning rate will converge faster, but if it's too large, the algorithm may overshoot the minimum and never converge, bouncing around the sides of the bowl into eternity. Setting a max number of iterations will avoid potential infinite loops. \n",
    "\n",
    "A reasonable epsilon depends on how noisy the data is and how flexible the model is. Starting relatively high and stepping down will increase the precision of the model without running into too many iteration overflows.\n",
    "\n",
    "For *Æž*, there are some interesting techniques for adjusting the parameter as the algorithm approaches the optimal solution. Check out [Adagrad](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#AdaGrad) for an example.\n",
    "\n",
    "Initializing the coefficients can also be done intelligently, but I'll just set them all to 0 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.30764503  0.20667802  0.14696395 -0.07014237]\n"
     ]
    }
   ],
   "source": [
    "initial_coefficients = np.array([0., 0., 0., 0.])\n",
    "coef = gradient_descent_regression(feature_matrix, y, initial_coefficients, 6e-5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x104013fd0>,\n",
       " <matplotlib.lines.Line2D at 0x105dc8950>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5vDHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105b089d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_prediction_X = np.array([x/10. for x in range(40)])\n",
    "model_prediction_matrix = np.zeros(40*4)\n",
    "model_prediction_matrix.shape = (40, 4)\n",
    "model_prediction_matrix[:,0] = 1\n",
    "model_prediction_matrix[:,1] = model_prediction_X\n",
    "model_prediction_matrix[:,2] = model_prediction_X**2\n",
    "model_prediction_matrix[:,3] = model_prediction_X**3\n",
    "\n",
    "predictions = predict_output(model_prediction_matrix, coef)\n",
    "\n",
    "plt.plot(X, y, '*', model_prediction_X, predictions, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad. To improve the model, we could try adding or subtracting features, or adding a regularization term to the cost function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "nikola": {
   "category": "",
   "date": "2016-01-18 17:46:22 UTC+08:00",
   "description": "",
   "link": "",
   "slug": "multiple-regression-in-python-gradient-descent",
   "tags": "python, machine-learning, statistics, regression",
   "title": "Multiple Regression in Python- Gradient Descent",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
